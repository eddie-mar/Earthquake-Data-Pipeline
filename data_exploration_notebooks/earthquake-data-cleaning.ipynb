{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd84a4f6-0448-4f27-9165-f278841b9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3422737a-dbb7-42ca-b8e5-723a3e0e49fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/10 21:07:05 WARN Utils: Your hostname, recurSe resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/08/10 21:07:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/08/10 21:07:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('earthquake-data-cleaning').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af37e31-82b3-4819-8ef0-54b09652fc63",
   "metadata": {},
   "source": [
    "Note that we will be only using the sample data for earthquake-data-wth-countries.csv which was only taken from 10000 rows of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebad4018-909b-4d93-8ac3-14d526d7fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option('header', 'true').option('inferSchema', 'true').csv('earthquake-data-wth-countries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1051f2-48af-41a0-8aaa-0182ebb2adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------+----------+------------+-----+-----+-------+----+----------+--------------------+--------+\n",
      "|               place|         time|magnitude|       lat|        long|depth|alert|tsunami|  tz|      type|             country|  region|\n",
      "+--------------------+-------------+---------+----------+------------+-----+-----+-------+----+----------+--------------------+--------+\n",
      "|8km SSW of Lytle ...|-631157391770|     2.58|34.1911667|    -117.522| 4.49| null|      0|null|earthquake|United States of ...|Americas|\n",
      "|24km WNW of Searl...|-631215832260|     2.01|35.8593333|-117.6506667|  0.0| null|      0|null|earthquake|United States of ...|Americas|\n",
      "|28km N of El Sauz...|-631241139690|      3.3|32.1433333|-116.6288333|  6.0| null|      0|null|earthquake|              Mexico|Americas|\n",
      "|1km SSW of Artesi...|-631251141040|     1.83|33.8561667|-118.0893333| 0.25| null|      0|null|earthquake|United States of ...|Americas|\n",
      "|16km SE of Primo ...|-631284369930|     3.02|    32.113|-116.8063333|  6.0| null|      0|null|earthquake|              Mexico|Americas|\n",
      "|south of the Fiji...|-631286334600|     null|   -26.927|    -176.566| 15.0| null|      0|null|earthquake|                Fiji| Oceania|\n",
      "|10 km SSW of Sawa...|-631292588380|     null|    35.793|     140.453| 35.0| null|      0|null|earthquake|               Japan|    Asia|\n",
      "|91 km NNE of Lase...|-631331600890|     null|    -5.923|     111.759|605.0| null|      0|null|earthquake|           Indonesia|    Asia|\n",
      "|Kermadec Islands ...|-631351025130|     null|   -27.889|    -177.108|135.0| null|      0|null|earthquake|                null|    null|\n",
      "|1km SW of Westwoo...|-631369460570|     1.82|34.0471667|   -118.4385|  6.0| null|      0|null|earthquake|United States of ...|Americas|\n",
      "|2 km SSE of Furao...|-631374120000|     null|    17.017|     121.808| 35.0| null|      0|null|earthquake|         Philippines|    Asia|\n",
      "|15 km NE of Siman...|-631388218290|     null|     17.58|     121.946| 35.0| null|      0|null|earthquake|         Philippines|    Asia|\n",
      "|7 km N of Agbanna...|-631400163400|     7.21|    17.439|     121.538| 15.0| null|      0|null|earthquake|         Philippines|    Asia|\n",
      "|21km SW of Little...|-631402302400|     2.03|35.7918333|     -118.05|  6.0| null|      0|null|earthquake|United States of ...|Americas|\n",
      "|33 km SSE of Adak...|-631448307640|     null|    51.584|    -176.509| 35.0| null|      0|null|earthquake|                null|    null|\n",
      "|east of the South...|-631460084000|     null|   -59.169|     -20.328| 15.0| null|      0|null|earthquake|                null|    null|\n",
      "|174 km NW of Sant...|-631474473850|     null|    40.271|     -29.346| 15.0| null|      0|null|earthquake|            Portugal|  Europe|\n",
      "|162 km ENE of San...|-631483741940|     null|    40.191|     -29.486| 15.0| null|      0|null|earthquake|            Portugal|  Europe|\n",
      "|east of the South...|-631497764890|     6.68|   -60.052|     -21.755| 10.0| null|      0|null|earthquake|                null|    null|\n",
      "|193 km WNW of Asa...|-631508164560|     null|   -13.124|     -174.38| 35.0| null|      0|null|earthquake|               Samoa| Oceania|\n",
      "+--------------------+-------------+---------+----------+------------+-----+-----+-------+----+----------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46e4e64-8ea6-4b0b-8674-e109d7fa4ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- place: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- magnitude: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- alert: string (nullable = true)\n",
      " |-- tsunami: integer (nullable = true)\n",
      " |-- tz: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24630e-eca7-48d0-864b-df54875ba8f4",
   "metadata": {},
   "source": [
    "Let us write the dataframe into parquet first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e05b021-f881-45e4-9983-3c79e0a513a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.repartition(4).write.parquet('parquet/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b09d0c-8c29-4c65-a90f-218627770448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('parquet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872ecdb-7402-4026-b199-0e86fe0deaa4",
   "metadata": {},
   "source": [
    "I have targetted the data cleaning procedures needed base on the data exploration I've done in pandas. First, let's convert the time column into a useful and readable format. Also, let's check if there are no invalid time or out of range time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876fd8a2-4597-4650-b52b-04b408563702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fmt_time = df.withColumn('earthquake_datetime', from_unixtime(col('time')/1000)). \\\n",
    "    withColumn('earthquake_datetime', to_timestamp('earthquake_datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82746f1f-1a6a-4b66-95cf-d23597f380dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- place: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- magnitude: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- alert: string (nullable = true)\n",
      " |-- tsunami: integer (nullable = true)\n",
      " |-- tz: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- earthquake_datetime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fmt_time.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99162058-3ad1-4050-8db6-7aec814b6093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fmt_time.filter((df_fmt_time.earthquake_datetime > datetime.fromisoformat('1900-01-01')) & (df_fmt_time.earthquake_datetime < datetime.now())).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279725d5-1129-41dd-86df-46176b997869",
   "metadata": {},
   "source": [
    "The filtered dataframe has still the same counts as the original dataframe. The column is also timestamp. Let's now proceed to data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15644be3-9ee5-49ad-a50a-9effeb8f365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fmt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd4e88b-a6d2-4dc6-a86d-b7cae75dbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f40e2a-6dfa-47cd-add2-83201c833756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = (df\n",
    "    .withColumnRenamed('lat', 'latitude')\n",
    "    .withColumnRenamed('long', 'longitude')\n",
    "    .select('place', 'earthquake_datetime', 'magnitude', 'latitude', 'longitude', 'depth', 'country', 'region', 'alert', 'tsunami', 'type')\n",
    "    .filter(\n",
    "        (F.col('magnitude') >= -1) &\n",
    "        (F.col('magnitude') <= 10) &\n",
    "        (F.col('magnitude').isNotNull())\n",
    "    )\n",
    "    .filter(\n",
    "        (F.col('latitude') >= -90) &\n",
    "        (F.col('latitude') <= 90)\n",
    "    )\n",
    "    .filter(\n",
    "        (F.col('longitude') >= -180) &\n",
    "        (F.col('longitude') <= 180)\n",
    "    )\n",
    "    .filter(\n",
    "        (F.col('earthquake_datetime') >= datetime.fromisoformat('1900-01-01')) &\n",
    "        (F.col('earthquake_datetime') <= datetime.fromisoformat('2025-06-30'))\n",
    "    )\n",
    "    .dropDuplicates(subset=['place', 'earthquake_datetime'])\n",
    "    .na.fill({'depth': 0})\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51ef2f09-936f-47b8-9d38-5fa43ca69e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7635"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a85de2e-06c2-4626-979e-f1bf7225d235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------+----------+------------+-----+--------------------+--------+-----+-------+------------+\n",
      "|               place|earthquake_datetime|magnitude|  latitude|   longitude|depth|             country|  region|alert|tsunami|        type|\n",
      "+--------------------+-------------------+---------+----------+------------+-----+--------------------+--------+-----+-------+------------+\n",
      "|0 km E of Rio Del...|1940-10-22 19:01:00|      4.5|      40.5|      -124.1|  0.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0 km NNE of Ayahu...|1942-11-18 08:19:34|     5.66|   -14.201|     -73.056| 15.0|                Peru|Americas| null|      0|  earthquake|\n",
      "|0 km NNE of K?r?k...|1938-05-14 14:55:25|     5.36|    39.853|      33.509| 15.0|              Turkey|    Asia| null|      0|  earthquake|\n",
      "|0 km NNW of Kirtl...|1943-03-09 12:25:25|      4.5|    41.628|     -81.309|  7.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0 km NNW of Ridge...|1945-05-17 23:06:47|      4.6|     36.82|     -121.37|  0.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0 km NNW of Zugli...|1949-02-04 06:29:22|     5.39|    46.464|      13.023| 10.0|               Italy|  Europe| null|      0|  earthquake|\n",
      "|0 km NW of East R...|1949-08-08 19:00:03|      3.3|     37.95|     -122.32|  0.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0 km S of Kleinlo...|1936-10-03 23:48:35|     5.45|    47.147|      14.849| 10.0|             Austria|  Europe| null|      0|  earthquake|\n",
      "|0 km WNW of Adelb...|1946-05-30 11:41:19|     5.86|    46.493|       7.555| 15.0|         Switzerland|  Europe| null|      0|  earthquake|\n",
      "|0 km WSW of Terni...|1939-09-18 08:14:35|     5.49|    47.715|      16.033| 15.0|             Austria|  Europe| null|      0|  earthquake|\n",
      "|0km E of Desert H...|1947-09-13 04:16:23|     2.67|33.9608333|-116.4998333|  6.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km ENE of Colton...|1940-07-07 09:50:53|     3.56|34.0763333|-117.3091667|11.94|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km ENE of East L...|1949-02-23 09:39:46|     1.95|   34.0325|-118.1648333| 4.64|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km ENE of Glendo...|1936-11-19 10:08:16|     1.98|34.1373333|-117.8611667| 0.01|United States of ...|Americas| null|      0|quarry blast|\n",
      "|0km ENE of Ocotil...|1940-10-26 19:21:24|     3.22|33.1438333|   -116.1285|  6.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km ESE of Desert...|1948-12-07 12:53:28|     2.48|33.9601667|-116.4981667|  6.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km ESE of Lakela...|1948-04-05 18:28:48|     2.82|33.6378333|   -117.3425|  6.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km ESE of Yorba ...|1949-12-10 10:13:45|     2.99|33.8873333|   -117.8095|  6.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km N of Carpinte...|1941-10-07 20:05:44|     2.86|34.4016667|-119.5178333|  6.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "|0km N of Rancho M...|1948-12-08 15:41:21|     2.69|   33.7435|-116.4133333|  6.0|United States of ...|Americas| null|      0|  earthquake|\n",
      "+--------------------+-------------------+---------+----------+------------+-----+--------------------+--------+-----+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9650282-afa4-49e2-bee8-60354909a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- place: string (nullable = true)\n",
      " |-- earthquake_datetime: timestamp (nullable = true)\n",
      " |-- magnitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- depth: double (nullable = false)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- alert: string (nullable = true)\n",
      " |-- tsunami: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca60c29-9fc8-474c-ae8c-d19fe1f40374",
   "metadata": {},
   "source": [
    "For the cleaning, we have converted the time (milliseconds from the epoch) to a useful and readable datetime format. We have also removed the tz column which has very small non-null values.<br>\n",
    "We have removed null magnitudes and values that are out of range. Same for depth, latitude, and longitude. We have transformed null depth values to 0 and lastly, we dropped duplicate rows base on place and time.<br>\n",
    "We can now stage the data to the warehouse and do some further dbt transformations to create data models.\n",
    "\n",
    "Note: This is just trial cleaning so we can interactively watch the process. Official script is stored in the pipeline folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ad1c4-7ac1-4501-b47f-37efe5b35258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
